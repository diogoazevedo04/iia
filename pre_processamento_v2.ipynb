{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed549ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eabf8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A carregar o dataset original\n",
      "Dataset Original carregado: 515738 linhas, 17 colunas\n"
     ]
    }
   ],
   "source": [
    "print(\"A carregar o dataset original\")\n",
    "try:\n",
    "    df = pd.read_csv(\"Hotel_Reviews.csv\")\n",
    "    print(f\"Dataset Original carregado: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: O ficheiro 'Hotel_Reviews.csv' n칚o foi encontrado. Verifica a pasta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a87f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A limpar dados ruidosos\n",
      "Limpeza de textos padr칚o conclu칤da.\n"
     ]
    }
   ],
   "source": [
    "print(\"A limpar dados ruidosos\")\n",
    "\n",
    "# O Booking.com preenche reviews vazias com \"No Negative\" ou \"No Positive\".\n",
    "# Isto confunde a IA (ela acha que a palavra \"Negative\" est치 no texto).\n",
    "# Substitu칤mos por string vazia.\n",
    "df[\"Negative_Review\"] = df[\"Negative_Review\"].replace(\"No Negative\", \"\")\n",
    "df[\"Positive_Review\"] = df[\"Positive_Review\"].replace(\"No Positive\", \"\")\n",
    "\n",
    "# Substituir valores vazios reais (NaN) por string vazia\n",
    "df[\"Negative_Review\"] = df[\"Negative_Review\"].fillna(\"\")\n",
    "df[\"Positive_Review\"] = df[\"Positive_Review\"].fillna(\"\")\n",
    "\n",
    "print(\"Limpeza de textos padr칚o conclu칤da.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e660ca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun칞칚o de processamento definida.\n"
     ]
    }
   ],
   "source": [
    "def processar_texto(row):\n",
    "    \"\"\"\n",
    "    Combina as reviews positiva e negativa e adiciona contexto (Nome do Hotel e Endere칞o).\n",
    "    N칚o removemos stopwords para manter a sem칙ntica para modelos Transformer.\n",
    "    \"\"\"\n",
    "    # Juntar as partes positiva e negativa\n",
    "    review_texto = (str(row[\"Negative_Review\"]) + \" \" + str(row[\"Positive_Review\"])).strip()\n",
    "    \n",
    "    # Se, depois de limpar, a review estiver vazia, retorna vazio (ser치 removida depois)\n",
    "    if not review_texto:\n",
    "        return np.nan\n",
    "    \n",
    "    # ESTRAT칄GIA RAG: Injetar Metadados no Texto\n",
    "    # O modelo de busca vai ler isto tudo junto. \n",
    "    # Ajuda a encontrar \"Hotel em Londres\" porque a palavra \"London\" passa a fazer parte do texto vetorial.\n",
    "    texto_final = (\n",
    "        f\"Hotel Name: {row['Hotel_Name']}. \"\n",
    "        f\"Location: {row['Hotel_Address']}. \"\n",
    "        f\"Review: {review_texto}\"\n",
    "    )\n",
    "    \n",
    "    # Limpeza Leve (apenas remover espa칞os duplos e quebras de linha)\n",
    "    texto_final = \" \".join(texto_final.split())\n",
    "    \n",
    "    return texto_final\n",
    "\n",
    "print(\"Fun칞칚o de processamento definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12903d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A criar a coluna de Texto Enriquecido\n",
      "Processamento conclu칤do. Linhas v치lidas restantes: 515501\n"
     ]
    }
   ],
   "source": [
    "print(\"A criar a coluna de Texto Enriquecido\")\n",
    "\n",
    "# Aplica a fun칞칚o a todas as linhas do DataFrame\n",
    "df['review'] = df.apply(processar_texto, axis=1)\n",
    "\n",
    "# Remove linhas que ficaram vazias depois do processamento (reviews sem texto 칰til)\n",
    "df = df.dropna(subset=['review'])\n",
    "\n",
    "print(f\"Processamento conclu칤do. Linhas v치lidas restantes: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63273330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游늵 A iniciar redu칞칚o inteligente de 515501 linhas...\n",
      "   - Reviews curtas removidas. Restam: 515332\n",
      "   - A recolher aprox. 4166 reviews por pa칤s...\n",
      "Redu칞칚o conclu칤da. Temos 24996 linhas prontas para o NLP.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TAMANHO_FINAL = 40000 \n",
    "\n",
    "print(f\"A iniciar redu칞칚o inteligente de {len(df)} linhas...\")\n",
    "\n",
    "# 1. FILTRO DE QUALIDADE (Riqueza Sem칙ntica)\n",
    "# Mantemos apenas reviews com mais de 15 palavras\n",
    "df['word_count'] = df['review'].apply(lambda x: len(str(x).split()))\n",
    "df_rico = df[df['word_count'] >= 15].copy()\n",
    "\n",
    "print(f\"   - Reviews curtas removidas. Restam: {len(df_rico)}\")\n",
    "\n",
    "# 2. AMOSTRAGEM ESTRATIFICADA (Balanceamento Geogr치fico)\n",
    "df_rico['Country'] = df_rico['Hotel_Address'].apply(lambda x: x.split()[-1])\n",
    "\n",
    "paises = df_rico['Country'].unique()\n",
    "linhas_por_pais = int(TAMANHO_FINAL / len(paises))\n",
    "\n",
    "dfs_temp = []\n",
    "print(f\"A recolher aprox. {linhas_por_pais} reviews por pa칤s...\")\n",
    "\n",
    "for pais in paises:\n",
    "    df_pais = df_rico[df_rico['Country'] == pais]\n",
    "    if len(df_pais) > linhas_por_pais:\n",
    "        df_pais = df_pais.sample(n=linhas_por_pais, random_state=42)\n",
    "    dfs_temp.append(df_pais)\n",
    "\n",
    "df_final = pd.concat(dfs_temp).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Redu칞칚o conclu칤da. Temos {len(df_final)} linhas prontas para o NLP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc6ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A aplicar PLN: Extra칞칚o de Keywords\n",
      "Extra칞칚o conclu칤da! Exemplo da 1춹 linha: made, via, booking, booked, next\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "print(\"A extrair keywords nas reviews selecionadas...\")\n",
    "\n",
    "STOPWORDS = {\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', \n",
    "    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n",
    "    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', \n",
    "    'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', \n",
    "    'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n",
    "    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n",
    "    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', \n",
    "    'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', \n",
    "    'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', \n",
    "    'weren', 'won', 'wouldn', 'hotel', 'room', 'staff', 'stay', 'location', 'would', 'could'\n",
    "}\n",
    "\n",
    "def extrair_keywords_robusto(texto):\n",
    "    if pd.isna(texto) or texto == \"\":\n",
    "        return \"\"\n",
    "    palavras = re.findall(r'\\b[a-zA-Z]{3,}\\b', str(texto).lower())\n",
    "    palavras_uteis = [p for p in palavras if p not in STOPWORDS]\n",
    "    contagem = Counter(palavras_uteis)\n",
    "    top_5 = [palavra for palavra, freq in contagem.most_common(5)]\n",
    "    return \", \".join(top_5)\n",
    "\n",
    "df_final['keywords_pln'] = df_final['review'].apply(extrair_keywords_robusto)\n",
    "\n",
    "colunas_uteis = [\n",
    "    'Hotel_Name', \n",
    "    'Hotel_Address', \n",
    "    'review', \n",
    "    'Negative_Review', \n",
    "    'Positive_Review',\n",
    "    'keywords_pln',  \n",
    "    'Average_Score', \n",
    "    'Tags',\n",
    "    'lat', \n",
    "    'lng'\n",
    "]\n",
    "\n",
    "df_final = df_final[colunas_uteis]\n",
    "\n",
    "print(f\"A guardar ficheiro final...\")\n",
    "df_final.to_csv(\"Hotel_Reviews_processed.csv\", index=False)\n",
    "print(\"Csv criado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
